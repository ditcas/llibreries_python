{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is pandas and Data structures\n",
    "\n",
    "- pandas contanins data structures and data manipulation tools designed to make data cleaning and analysis fast and easy in Python.\n",
    "\n",
    "- It is designed for working with tabular or heterogeneous data. Numpy, by contrast, is best suited for working with homogeneous numerical array data.\n",
    "\n",
    "- Its two workhorse data structures are Series and DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Series\n",
    "\n",
    "- One-dimensional array-like object containing a sequence of values (of similar types to Numpy types) and an associated array of data labels, called its index.\n",
    "\n",
    "- A way to think about a Series is as a fixed-length, ordered dict, as it is a mapping of index values to data values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    4\n",
      "1    7\n",
      "2   -5\n",
      "3    3\n",
      "dtype: int64\n",
      "Ohio      35000\n",
      "Texas     71000\n",
      "Oregon    16000\n",
      "Utah       5000\n",
      "dtype: int64\n",
      "California        NaN\n",
      "Ohio          35000.0\n",
      "Oregon        16000.0\n",
      "Texas         71000.0\n",
      "dtype: float64\n",
      "California        NaN\n",
      "Oregon        16000.0\n",
      "Ohio          35000.0\n",
      "Utah          71000.0\n",
      "dtype: float64\n",
      "state\n",
      "California        NaN\n",
      "Ohio          35000.0\n",
      "Oregon        16000.0\n",
      "Texas         71000.0\n",
      "Name: population, dtype: float64\n",
      "0    c\n",
      "1    a\n",
      "2    b\n",
      "2    b\n",
      "0    c\n",
      "1    a\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Create a Series from a list\n",
    "obj = pd.Series([4, 7, -5, 3]) # Since we don't specify an index for the data, a default one consisting of the integers 0 through n-1 is created.\n",
    "print(obj)\n",
    "obj.index\n",
    "obj.values\n",
    "\n",
    "# Assignar indexs a posteriori\n",
    "obj.index = [1, 2, 3, 4]\n",
    "\n",
    "# Assignar indexs en definir\n",
    "obj2 = pd.Series([4, 7, -5, 3], index = [\"d\", \"b\", \"a\", \"c\"])\n",
    "\n",
    "# Create a Series from a dictionary\n",
    "sdata = {\"Ohio\": 35000, \"Texas\": 71000, \"Oregon\": 16000, \"Utah\": 5000}\n",
    "obj3 = pd.Series(sdata)\n",
    "print(obj3)\n",
    "\n",
    "# Redefinir indexs, canviant ordre, afegint, traient\n",
    "\n",
    "# Opció 1, en la creació\n",
    "states = [\"California\", \"Ohio\", \"Oregon\", \"Texas\"]\n",
    "obj4 = pd.Series(sdata, index = states)\n",
    "print(obj4)\n",
    "\n",
    "# Opció 2, després en un nou objecte\n",
    "obj5 = obj4.reindex([\"California\", \"Oregon\", \"Ohio\", \"Utah\"]) # Si no estava la label en l'anterior, col·loca NaN\n",
    "#print(obj5)\n",
    "\n",
    "obj6 = obj4.reindex([\"California\", \"Oregon\", \"Ohio\", \"Utah\"], method = \"ffill\") # Si hi ha valors NaN, els reemplaça pel valor de la fila prèvia o si axis=\"columns\", pel de la columna prèvia.\n",
    "print(obj6)\n",
    "\n",
    "# Series object and its index have a \"name\" attribute.\n",
    "obj4.name = \"population\"\n",
    "obj4.index.name = \"state\"\n",
    "print(obj4)\n",
    "\n",
    "# Indexar una Serie de valors repetits a partir d'una Serie dels valors únics - get_indexer\n",
    "\n",
    "srep = pd.Series([\"c\", \"a\", \"b\", \"b\", \"c\", \"a\"]) # els índexs ara són 0,1,2,3,4,5\n",
    "unique = pd.Series(srep.unique()) #method unique a la secció Descriptive Statistics dels apunts.\n",
    "\n",
    "arrindex = pd.Index(unique).get_indexer(srep)\n",
    "srep2 = srep.reindex(index=arrindex)\n",
    "print(srep2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame\n",
    "\n",
    "- A DataFrame represents a rectangular table of data and contains an ordered collection of columns, each of which can be a different value type (numeric, string, boolean, etc.). The DataFrame has both row and column index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    state  year  pop\n",
      "0    Ohio  2000  1.5\n",
      "1    Ohio  2001  1.7\n",
      "2    Ohio  2002  3.6\n",
      "3  Nevada  2001  2.4\n",
      "4  Nevada  2002  2.9\n",
      "5  Nevada  2003  3.2\n",
      "       year state  pop  crimes\n",
      "one       0     0  0.0       0\n",
      "two       0     0  0.0       0\n",
      "three     0     0  0.0       0\n",
      "four      0     0  0.0       0\n",
      "five      0     0  0.0       0\n",
      "six       0     0  0.0       0\n",
      "0    c\n",
      "1    a\n",
      "2    b\n",
      "2    b\n",
      "0    c\n",
      "1    a\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# OPCIÓ 1: From a dict of equal-length lists\n",
    "\n",
    "data = {\"state\": [\"Ohio\", \"Ohio\", \"Ohio\", \"Nevada\", \"Nevada\", \"Nevada\"],\n",
    "\"year\": [2000, 2001, 2002, 2001, 2002, 2003],\n",
    "\"pop\": [1.5, 1.7, 3.6, 2.4, 2.9, 3.2]}\n",
    "\n",
    "frame = pd.DataFrame(data)\n",
    "print(frame)\n",
    "\n",
    "# Definir indexs, canviar ordre de les columnes en crear el DataFrame\n",
    "frame2 = pd.DataFrame(data, index = [\"one\", \"two\", \"three\", \"four\", \"five\", \"six\"] , columns = [\"year\", \"state\", \"pop\"])\n",
    "# print(frame2)\n",
    "\n",
    "# Definir indexs a posteriori mitjançant un pd.Index([ ]), una columna del Dataframe o el metohd reindex.\n",
    "#frame22 = frame.set_index(pd.Index([\"one\", \"two\", \"three\", \"four\", \"five\", \"six\"]))\n",
    "\n",
    "#frame22 = frame.set_index(\"state\")\n",
    "\n",
    "frame22 = frame.reindex(index = [\"one\", \"two\", \"three\", \"four\", \"five\", \"six\"], columns=[\"year\", \"state\", \"pop\", \"crimes\"], fill_value=0) # Si afegim una nova columna que tindrà valors NaN, podem usar argument fill_value per omplir-los.\n",
    "\n",
    "print(frame22)\n",
    "\n",
    "# OPCIÓ 2: From ndarrays from Numpy\n",
    "\n",
    "frame1 = pd.DataFrame(np.arange(9.).reshape((3,3)), columns=list(\"bcd\"), index=[\"Ohio\", \"Texas\", \"Colorado\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Nevada  Ohio\n",
      "2000     NaN   1.5\n",
      "2001     2.4   1.7\n",
      "2002     2.9   3.6\n",
      "state  Nevada  Ohio\n",
      "year               \n",
      "2000      NaN   1.5\n",
      "2001      2.4   1.7\n",
      "2002      2.9   3.6\n",
      "           employees  revenues\n",
      "Apple         147000    274515\n",
      "Samsung       267937    200734\n",
      "Google        135301    182527\n",
      "Microsoft     163000    143015\n",
      "Huawei        197000    129184\n",
      "Dell          158000     92224\n",
      "Facebook       58604     85965\n",
      "Foxconn       878429    181945\n",
      "Sony          109700     84893\n"
     ]
    }
   ],
   "source": [
    "# OPCIÓ 3: From a nested dict of dicts\n",
    "\n",
    "popdata = {\"Nevada\": {2001: 2.4, 2002: 2.9}, \"Ohio\": {2000: 1.5, 2001: 1.7, 2002: 3.6}}\n",
    "frame3 = pd.DataFrame(popdata, index = [2000, 2001, 2002]) # the outer dict keys are the columns and the inner keys are the rows indices. He afegit index = per ordenar els anys al meu gust.\n",
    "print(frame3)\n",
    "\n",
    "# index and columns have their name attributes\n",
    "\n",
    "frame3.index.name = \"year\"\n",
    "frame3.columns.name = \"state\"\n",
    "\n",
    "print(frame3)\n",
    "\n",
    "# OPCIÓ 4: From Series\n",
    "\n",
    "data_emp = {'Apple': 147000, 'Samsung': 267937, 'Google': 135301, 'Microsoft': 163000, 'Huawei': 197000, 'Dell': 158000, 'Facebook': 58604, 'Foxconn': 878429, 'Sony': 109700}\n",
    "employees = pd.Series(data_emp, name='Tech Employees')\n",
    "\n",
    "data_rev = {'Apple': 274515, 'Samsung': 200734, 'Google': 182527, 'Microsoft': 143015, 'Huawei': 129184, 'Dell': 92224, 'Facebook': 85965, 'Foxconn': 181945, 'Sony': 84893}\n",
    "revenues = pd.Series(data_rev, name=\"Tech Revenues\")\n",
    "\n",
    "df = pd.DataFrame({\"employees\": employees, \"revenues\": revenues})\n",
    "print(df)\n",
    "\n",
    "# ALTRES OPCIONS: Des de una llista de dicionaris, des de una llista de llistes, \n",
    "# [{'A': 1, 'B': 2, 'C': 3}, {'A': 4, 'B': 5, 'C': 6}]\n",
    "# [[1, 2], [3, 4], [5, 6]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series: Selection\n",
    "\n",
    "- isnull and notnull to detect missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d    4\n",
      "b    7\n",
      "c    3\n",
      "dtype: int64\n",
      "d     True\n",
      "b    False\n",
      "a    False\n",
      "c     True\n",
      "dtype: bool\n",
      "d    4\n",
      "c    3\n",
      "dtype: int64\n",
      "Els dos últims:\n",
      " a   -5\n",
      "c    3\n",
      "dtype: int64\n",
      "De principi a fi de dos en dos:\n",
      " d    4\n",
      "a   -5\n",
      "dtype: int64\n",
      "Els elements de b a c:\n",
      " b    7\n",
      "a   -5\n",
      "c    3\n",
      "dtype: int64\n",
      "L'element b és: 7\n",
      "California     True\n",
      "Ohio          False\n",
      "Oregon        False\n",
      "Texas         False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "obj2 = pd.Series([4, 7, -5, 3], index = [\"d\", \"b\", \"a\", \"c\"])\n",
    "\n",
    "# Filtrar\n",
    "dat2 = obj2[obj2 > 0] \n",
    "print(dat2)\n",
    "\n",
    "\"b\" in obj2 # True. Saber si un label hi és en la Serie\n",
    "\n",
    "mask = obj2.isin([3, 4])\n",
    "print(mask) # True o False segons si és 3 o 4 o no.\n",
    "print(obj2[mask])\n",
    "\n",
    "\n",
    "# Slicing\n",
    "\n",
    "print(\"Els dos últims:\\n\", obj2[-2:]) \n",
    "print(\"De principi a fi de dos en dos:\\n\", obj2[::2])\n",
    "print(\"Els elements de b a c:\\n\", obj2[\"b\":\"c\"]) # Slicing per label, INCLOU INICI I FI\n",
    "print(\"L'element b és:\", obj2[\"b\"])\n",
    "\n",
    "\n",
    "# Detectar missing data\n",
    "\n",
    "sdata = {\"Ohio\": 35000, \"Texas\": 71000, \"Oregon\": 16000, \"Utah\": 5000}\n",
    "states = [\"California\", \"Ohio\", \"Oregon\", \"Texas\"]\n",
    "obj4 = pd.Series(sdata, index = states)\n",
    "\n",
    "print(pd.isnull(obj4)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame: Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    state  year  pop\n",
      "0    Ohio  2000  1.5\n",
      "1    Ohio  2001  1.7\n",
      "2    Ohio  2002  3.6\n",
      "3  Nevada  2001  2.4\n",
      "4  Nevada  2002  2.9\n",
      "5  Nevada  2003  3.2\n",
      "  state  pop\n",
      "0  Ohio  1.5\n",
      "1  Ohio  1.7\n",
      "  state  pop\n",
      "0  Ohio  1.5\n",
      "1  Ohio  1.7\n",
      "    state  year  pop\n",
      "1    Ohio  2001  1.7\n",
      "3  Nevada  2001  2.4\n",
      "  state  year  pop\n",
      "0  Ohio  2000  1.5\n",
      "1  Ohio  2001  1.7\n",
      "2  Ohio  2002  3.6\n",
      "  state  year  pop\n",
      "0  Ohio  2000  1.5\n",
      "1  Ohio  2001  1.7\n",
      "2  Ohio  2002  3.6\n",
      "  state  year  pop\n",
      "0  Ohio  2000  1.5\n",
      "1  Ohio  2001  1.7\n"
     ]
    }
   ],
   "source": [
    "data = {\"state\": [\"Ohio\", \"Ohio\", \"Ohio\", \"Nevada\", \"Nevada\", \"Nevada\"],\n",
    "\"year\": [2000, 2001, 2002, 2001, 2002, 2003],\n",
    "\"pop\": [1.5, 1.7, 3.6, 2.4, 2.9, 3.2]}\n",
    "\n",
    "frame = pd.DataFrame(data)\n",
    "print(frame)\n",
    "\n",
    "frame.index # Només els índexs de les files. En aquest cas, no definits, 0,1,2,3,4,5\n",
    "\n",
    "frame.values # Només els valors\n",
    "\n",
    "frame.columns # Només els índexs de les columnes\n",
    "\n",
    "frame[\"state\"] # Seleccionar una columna. Equivalent: frame.state\n",
    "\n",
    "frame[0:2] # Seleccionar les dues primeres columnes. Usar enters pot portar a errors entre índexs i posició. Millor usar iloc.\n",
    "\n",
    "frame.loc[0] # Seleccionar una fila by label\n",
    "\n",
    "frame.loc[0:2, [\"state\", \"pop\"]] # Seleccionar un element, o una combinació de files i columnes. Slicing per labels, INCLOU INICI I FI\n",
    "\n",
    "frame.iloc[0, 1] # Seleccionar mitjançant posició (integers) i no label\n",
    "\n",
    "frame.head() # to view only the first five rows\n",
    "frame.tail(3) # to view only the last three rows\n",
    "\n",
    "# Saber si una columna o fila hi és en la taula\n",
    "\"year\" in frame.columns # True\n",
    "6 in frame.index # False\n",
    "\n",
    "# Mostrar True/False si data compleix certes condicions\n",
    "frame[\"pop\"] < 2\n",
    "\n",
    "# Mostrar data que compleix certes condicions\n",
    "print(frame[[\"state\", \"pop\"]][frame[\"pop\"] < 2]) # Veure state i pop dels que tenen pop < 2\n",
    "\n",
    "print(frame.loc[frame[\"pop\"] < 2, [\"state\", \"pop\"]]) # Equivalent a l'anterior\n",
    "\n",
    "print(frame[frame[\"year\"] == 2001]) # Files tal que year sigui 2001\n",
    "\n",
    "print(frame[frame[\"state\"].str.contains(\"Oh\")]) # Les files tal que state contingui la string Oh\n",
    "\n",
    "print(frame.loc[frame[\"state\"].str.contains(\"Oh\")]) # Equivalent a l'anterior. loc accepta boolean lists\n",
    "\n",
    "print(frame[frame[\"state\"].str.contains(\"Oh\")].loc[0:1]) # Les dos primeres files tal que state contingui la string Oh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series: Modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d    5\n",
      "b    7\n",
      "a   -5\n",
      "c    3\n",
      "dtype: int64\n",
      "d    5\n",
      "b    7\n",
      "a   -5\n",
      "c    3\n",
      "dtype: int64\n",
      "d    5\n",
      "b    7\n",
      "a   -5\n",
      "c    3\n",
      "e   -1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "obj2 = pd.Series([4, 7, -5, 3], index = [\"d\", \"b\", \"a\", \"c\"])\n",
    "\n",
    "# Eliminar un valor\n",
    "# del obj2[\"a\"]\n",
    "\n",
    "# Nova Serie havent eliminat valors \n",
    "obje = obj2.drop([\"b\", \"c\"]) # usar ,inplace = True per aplicar-ho al propi objecte\n",
    "\n",
    "print(obj2)\n",
    "\n",
    "# Modificar un valor per assignació\n",
    "obj2[\"d\"] = 5\n",
    "print(obj2)\n",
    "\n",
    "# Afegir un nou valor\n",
    "obj2[\"e\"] = -1\n",
    "print(obj2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame: Modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Nevada  Ohio\n",
      "2000     2.1   1.3\n",
      "2001     2.2   3.6\n",
      "2002     2.8   1.9\n",
      "      Nevada  Ohio\n",
      "2000     2.1   1.3\n",
      "2001     2.2   3.6\n",
      "2002     5.0   1.9\n",
      "      Nevada  Ohio\n",
      "2000     5.0   4.0\n",
      "2001     2.2   3.6\n",
      "2002     5.0   1.9\n",
      "      Nevada  Ohio\n",
      "2000     NaN   4.0\n",
      "2001     2.6   3.6\n",
      "2002     3.0   1.9\n",
      "      Nevada  Ohio  California  Exceed_Ohio\n",
      "2000     NaN   4.0           1         True\n",
      "2001     2.6   3.6           2         True\n",
      "2002     3.0   1.9           3        False\n",
      "      Nevada  Ohio  California  Exceed_Ohio\n",
      "2000     NaN   4.0           1         True\n",
      "2001     2.6   3.6           2         True\n",
      "2002     3.0   1.9           3        False\n",
      "2003     3.2   4.1           4         True\n",
      "      Nevada  Ohio  California  Exceed_Ohio\n",
      "2000     NaN   4.0           1        False\n",
      "2001     2.6   3.6           2        False\n",
      "2002     3.0   1.9           3         True\n",
      "2003     3.2   4.1           4        False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2000</th>\n",
       "      <th>2001</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ohio</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exceed_Ohio</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              2000   2001  2002   2003\n",
       "Ohio           4.0    3.6   1.9    4.1\n",
       "California       1      2     3      4\n",
       "Exceed_Ohio  False  False  True  False"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popdata = {\"Nevada\": {2001: 2.4, 2002: 2.9}, \"Ohio\": {2000: 1.5, 2001: 3.6, 2002: 1.9}}\n",
    "frame3 = pd.DataFrame(popdata, index = [2000, 2001, 2002]) \n",
    "\n",
    "# Modificar valors per nova assignació\n",
    "frame3[\"Nevada\"] = [2.1, 2.2, 2.8] # Si només posem un valor, s'assignaria el mateix a totes les files.\n",
    "frame3[\"Ohio\"][2000] = 1.3 # Modificar un element concret\n",
    "#print(frame3)\n",
    "\n",
    "frame3.loc[frame3[\"Nevada\"] > 2.5, [\"Nevada\"]] = 5 # Modificar valors d'una columna segons condició\n",
    "#print(frame3)\n",
    "\n",
    "frame3.loc[frame3.index == 2000, [\"Nevada\", \"Ohio\"]] = [5, 4] # Modificar valors de més d'una columna de manera personalitzada segons condició\n",
    "#print(frame3)\n",
    "\n",
    "\n",
    "# Modificar tota una columna a partir d'una Serie. Si no es posen tots els indexs, posa NaN.\n",
    "val = pd.Series([2.6, 3], index=[2001, 2002])\n",
    "frame3[\"Nevada\"] = val\n",
    "print(frame3)\n",
    "\n",
    "# Afegir una nova columna\n",
    "frame3[\"California\"] = [1, 2, 3]\n",
    "\n",
    "frame3[\"Exceed_Ohio\"] = frame3[\"Ohio\"] > 2.5 # Nova columna booleana\n",
    "print(frame3)\n",
    "\n",
    "# Afegir una nova fila\n",
    "dosmiltres = pd.DataFrame(data=[[3.2, 4.1, 4, True]], columns=frame3.columns, index=[2003])\n",
    "\n",
    "frame3 = pd.concat([frame3, dosmiltres], axis=0) # Concatenar dos o més DataFrames\n",
    "print(frame3)\n",
    "\n",
    "# Reemplaçar els valors d'una columna amb una recodificació\n",
    "boolrare = {True: False, False: True}\n",
    "frame3[\"Exceed_Ohio\"].replace(boolrare, inplace=True)\n",
    "print(frame3)\n",
    "\n",
    "# Eliminar una columna\n",
    "del frame3[\"Nevada\"]\n",
    "\n",
    "# Crear un nou objecte sense alguna columna o fila\n",
    "framec = frame3.drop(\"Ohio\", axis = 1) # usar ,inplace = True per aplicar-ho al propi objecte\n",
    "framef = frame3.drop(2000)\n",
    "\n",
    "# Transposar el DataFrame\n",
    "frame3.T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series: Operations\n",
    "\n",
    "- You can use Numpy functions or Numpy-like operations.\n",
    "\n",
    "- artihmetic methods: add (+), sub (-), div (/), floordiv (//), mul (*), pow (**). Si posem r al davant, radd, rsub... invertim ordre de l'operació: a - b equivalent a a.sub(b) equivalent a b.rsub(a)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d     8\n",
      "b    14\n",
      "a   -10\n",
      "c     6\n",
      "dtype: int64\n",
      "California         NaN\n",
      "Ohio           70000.0\n",
      "Oregon         32000.0\n",
      "Texas         142000.0\n",
      "Utah               NaN\n",
      "dtype: float64\n",
      "d    4\n",
      "b    7\n",
      "a    5\n",
      "c    3\n",
      "dtype: int64\n",
      "d     0\n",
      "b     0\n",
      "a   -10\n",
      "c     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "obj2 = pd.Series([4, 7, -5, 3], index = [\"d\", \"b\", \"a\", \"c\"])\n",
    "sdata = {\"Ohio\": 35000, \"Texas\": 71000, \"Oregon\": 16000, \"Utah\": 5000}\n",
    "obj3 = pd.Series(sdata)\n",
    "states = [\"California\", \"Ohio\", \"Oregon\", \"Texas\"]\n",
    "obj4 = pd.Series(sdata, index = states)\n",
    "\n",
    "print(obj2 * 2)\n",
    "\n",
    "print(obj3 + obj4) # Sumar els valors que tenen el mateix índex, els que no pot sumar, els converteix en NaN.\n",
    "\n",
    "print(np.abs(obj2)) # valor absolut. Funció Numpy.\n",
    "\n",
    "f = lambda x : x - abs(x)\n",
    "print(obj2.map(f)) # .map aplicar una funció a cada un dels elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame: Operations\n",
    "\n",
    "- artihmetic methods: add (+), sub (-), div (/), floordiv (//), mul (*), pow (**). Si posem r al davant, radd, rsub... invertim ordre de l'operació: a - b equivalent a a.sub(b) equivalent a b.rsub(a).\n",
    "\n",
    "- Numpy ufuncs also work with pandas objects,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            b    c    d\n",
      "Ohio      0.0  1.0  2.0\n",
      "Texas     3.0  4.0  5.0\n",
      "Colorado  6.0  7.0  8.0\n",
      "          b     d     e\n",
      "Utah    0.0   1.0   2.0\n",
      "Ohio    3.0   4.0   5.0\n",
      "Texas   6.0   7.0   8.0\n",
      "Oregon  9.0  10.0  11.0\n",
      "            b   c     d   e\n",
      "Colorado  NaN NaN   NaN NaN\n",
      "Ohio      3.0 NaN   6.0 NaN\n",
      "Oregon    NaN NaN   NaN NaN\n",
      "Texas     9.0 NaN  12.0 NaN\n",
      "Utah      NaN NaN   NaN NaN\n",
      "            b    c     d     e\n",
      "Colorado  6.0  7.0   8.0   NaN\n",
      "Ohio      3.0  1.0   6.0   5.0\n",
      "Oregon    9.0  NaN  10.0  11.0\n",
      "Texas     9.0  4.0  12.0   8.0\n",
      "Utah      0.0  NaN   1.0   2.0\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame(np.arange(9.).reshape((3,3)), columns=list(\"bcd\"), index=[\"Ohio\", \"Texas\", \"Colorado\"])\n",
    "\n",
    "df2 = pd.DataFrame(np.arange(12.).reshape((4,3)), columns=list(\"bde\"), index=[\"Utah\", \"Ohio\", \"Texas\", \"Oregon\"])\n",
    "\n",
    "print(df1)\n",
    "print(df2)\n",
    "\n",
    "print(df1 + df2) # Cal que índex de fila i columna coincideixin per poder sumar-los. Sinó, NaN.\n",
    "print(df1.add(df2, fill_value=0)) # Es pot usar els methods per operar(add, sub, div...) i l'argument fill_value per si un element només està en una taula, assignar-li valor a l'altra taula per sumar. Si l'element no està en cap de les dues taules, seguirà apareixent NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          b     d     e\n",
      "Utah    0.0   1.0   2.0\n",
      "Ohio    3.0   4.0   5.0\n",
      "Texas   6.0   7.0   8.0\n",
      "Oregon  9.0  10.0  11.0\n",
      "b    0.0\n",
      "d    1.0\n",
      "e    2.0\n",
      "Name: Utah, dtype: float64\n",
      "          b    d    e\n",
      "Utah    0.0  0.0  0.0\n",
      "Ohio    3.0  3.0  3.0\n",
      "Texas   6.0  6.0  6.0\n",
      "Oregon  9.0  9.0  9.0\n",
      "Utah       1.0\n",
      "Ohio       4.0\n",
      "Texas      7.0\n",
      "Oregon    10.0\n",
      "Name: d, dtype: float64\n",
      "          b    d    e\n",
      "Utah   -1.0  0.0  1.0\n",
      "Ohio   -1.0  0.0  1.0\n",
      "Texas  -1.0  0.0  1.0\n",
      "Oregon -1.0  0.0  1.0\n"
     ]
    }
   ],
   "source": [
    "# OPERATIONS BETWEEN DATAFRAME AND SERIES\n",
    "# Arithmetic between them matches the index of the Series on the DataFrame's columns, broadcasting down the rows.\n",
    "\n",
    "frame = pd.DataFrame(np.arange(12.).reshape((4,3)), index=[\"Utah\", \"Ohio\", \"Texas\", \"Oregon\"], columns=list(\"bde\"))\n",
    "\n",
    "series = frame.iloc[0] # La primera fila\n",
    "\n",
    "print(frame)\n",
    "print(series)\n",
    "\n",
    "print(frame - series) # resta la fila series a totes les files de frame lligant b-b, d-d, e-e. Si hi hagués algun índex sense match, NaN.\n",
    "\n",
    "# Si volem lligar índexs per files, i fer broadcast over the columns, cal usar els arithmetic methods: add, sub... i l'argument axis=\"index\"\n",
    "\n",
    "series2 = frame[\"d\"] # la columna d\n",
    "print(series2)\n",
    "\n",
    "print(frame.sub(series2, axis=\"index\")) # resta la columna d a totes les columnes de frame, lligant Utah, Ohio...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               b         d         e\n",
      "Utah   -0.619936  0.383376 -1.008632\n",
      "Ohio   -0.371243  0.958097 -0.199604\n",
      "Texas  -2.595658 -0.802796 -0.441220\n",
      "Oregon  0.540372  0.002627 -0.636958\n",
      "               b         d         e\n",
      "Utah    0.619936  0.383376  1.008632\n",
      "Ohio    0.371243  0.958097  0.199604\n",
      "Texas   2.595658  0.802796  0.441220\n",
      "Oregon  0.540372  0.002627  0.636958\n",
      "b    3.136030\n",
      "d    1.760894\n",
      "e    0.809028\n",
      "dtype: float64\n",
      "Utah      1.392008\n",
      "Ohio      1.329341\n",
      "Texas     2.154439\n",
      "Oregon    1.177330\n",
      "dtype: float64\n",
      "            b         d         e\n",
      "min -2.595658 -0.802796 -1.008632\n",
      "max  0.540372  0.958097 -0.199604\n",
      "            b      d      e\n",
      "Utah    -0.62   0.38  -1.01\n",
      "Ohio    -0.37   0.96  -0.20\n",
      "Texas   -2.60  -0.80  -0.44\n",
      "Oregon   0.54   0.00  -0.64\n"
     ]
    }
   ],
   "source": [
    "# FUNCTION APPLICATION AND MAPPING\n",
    "\n",
    "frame = pd.DataFrame(np.random.randn(4,3), index=[\"Utah\", \"Ohio\", \"Texas\", \"Oregon\"], columns=list(\"bde\"))\n",
    "print(frame)\n",
    "\n",
    "#Numpy function\n",
    "print(np.abs(frame)) \n",
    "\n",
    "# Applying a function on one-dimensional arrays to each column or row. - APPLY\n",
    "f = lambda x: x.max() - x.min()\n",
    "\n",
    "print(frame.apply(f)) # Aplica per columnes\n",
    "\n",
    "print(frame.apply(f, axis=\"columns\")) # aplica per files, és a dir, saltant columnes\n",
    "\n",
    "def g(x) : # Un altre exemple\n",
    "    return pd.Series([x.min(), x.max()], index=[\"min\", \"max\"])\n",
    "\n",
    "print(frame.apply(g))\n",
    "\n",
    "# Element-wise Python functions - APPLYMAP\n",
    "\n",
    "format = lambda x: \"%.2f\" % x # Formateja valors a floats amb dos decimals\n",
    "\n",
    "print(frame.applymap(format))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series: Sorting and ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "d    0\n",
      "dtype: int64\n",
      "d    0\n",
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "dtype: int64\n",
      "0    7.5\n",
      "1    1.0\n",
      "2    7.5\n",
      "3    5.0\n",
      "4    3.0\n",
      "5    2.0\n",
      "6    5.0\n",
      "7    5.0\n",
      "dtype: float64\n",
      "0    1.0\n",
      "1    8.0\n",
      "2    1.0\n",
      "3    3.0\n",
      "4    6.0\n",
      "5    7.0\n",
      "6    3.0\n",
      "7    3.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "obj = pd.Series(range(4), index=[\"d\", \"a\", \"b\", \"c\"])\n",
    "\n",
    "print(obj.sort_index()) # Ordenat pels índexs\n",
    "\n",
    "print(obj.sort_values()) # Ordenat pels valors\n",
    "\n",
    "series = pd.Series([7, -5, 7, 4, 2, 0, 4, 4])\n",
    "\n",
    "print(series.rank()) # amb el número 1, el valor més petit, i d'aquí en amunt. Si números repetits, se'ls otorga la mitjana de les posicions. Per exemple, els 4 estan en posició 4-5-6, per això els tres reben un 5. I els 7 estan en posició 7 i 8, per això reben un 7.5. Hi ha altres mètodes per valors repetits, com \"first\", \"max\", \"min\", \"dense\".\n",
    "\n",
    "print(series.rank(ascending = False, method = \"min\")) # amb 1 el valor més gran. Si repetits, la posició menor per tots.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame: Sorting and ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          d         a         b         c\n",
      "3 -1.771059  0.115122  0.257853 -0.912060\n",
      "2  0.139835 -0.203534  0.835837 -0.125360\n",
      "4 -1.335450  0.823848  0.422093  0.123598\n",
      "1 -0.759722  0.870042  0.266013 -0.078854\n",
      "     d    a    b    c\n",
      "3  1.0  2.0  1.0  1.0\n",
      "2  4.0  1.0  4.0  2.0\n",
      "4  2.0  3.0  3.0  4.0\n",
      "1  3.0  4.0  2.0  3.0\n",
      "     d    a    b    c\n",
      "3  4.0  2.0  1.0  3.0\n",
      "2  2.0  4.0  1.0  3.0\n",
      "4  4.0  1.0  2.0  3.0\n",
      "1  4.0  1.0  2.0  3.0\n"
     ]
    }
   ],
   "source": [
    "frame = pd.DataFrame(np.random.randn(4,4), index=[3, 2, 4, 1], columns=[\"d\", \"a\", \"b\", \"c\"])\n",
    "print(frame)\n",
    "\n",
    "frame.sort_index() # Per índexs fila\n",
    "frame.sort_index(axis=1) # Per índexs columna\n",
    "frame.sort_values(by=\"c\", ascending=False) # Per valors d'una columna, de gran a petit. Podem posar-hi més d'una columna by=[\"\", \"\"]\n",
    "\n",
    "print(frame.rank()) # Rang de petit a gran per columnes\n",
    "print(frame.rank(axis = \"columns\", ascending=False)) # Rang de gran a petit per files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Axis indexes with duplicate labels\n",
    "\n",
    "All of the examples we've looked at have had unique axis labels. While many pandas functions, like reindex, require that the labels be unique, it's not mandatory.\n",
    "\n",
    "The index's \"is_unique\" property can tell you whether its labels are unique or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive Statistics\n",
    "\n",
    "- Compared with the similar methods found on Numpy arrays, these ones have been built-in handling for missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    one  two\n",
      "a  1.40  NaN\n",
      "b  7.10 -4.5\n",
      "c   NaN  NaN\n",
      "d  0.75 -1.3\n",
      "one    9.25\n",
      "two   -5.80\n",
      "dtype: float64\n",
      "            one       two\n",
      "count  3.000000  2.000000\n",
      "mean   3.083333 -2.900000\n",
      "std    3.493685  2.262742\n",
      "min    0.750000 -4.500000\n",
      "25%    1.075000 -3.700000\n",
      "50%    1.400000 -2.900000\n",
      "75%    4.250000 -2.100000\n",
      "max    7.100000 -1.300000\n",
      "count     16\n",
      "unique     3\n",
      "top        a\n",
      "freq       8\n",
      "dtype: object\n",
      "['a' 'b' 'c']\n",
      "a    8\n",
      "b    4\n",
      "c    4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = np.array([[1.4, np.nan], [7.1, -4.5], [np.nan, np.nan], [0.75, -1.3]])\n",
    "df = pd.DataFrame(data, index=list(\"abcd\"), columns=[\"one\",\"two\"])\n",
    "print(df)\n",
    "\n",
    "print(df.sum()) # NA values are excluded. Si volem que els contempli i per tant aparegui NaN en la suma, skipna=False.  # Si volem sumar les files, axis=1.\n",
    "\n",
    "df.max() # valor màxim de cada columna\n",
    "\n",
    "df[\"one\"].idxmax() # index del valor màxim de la columna \"one\"\n",
    "\n",
    "df.cumsum() # Suma acumulativa\n",
    "\n",
    "df.nlargest(3, \"one\") # els tres registres amb valor més gran en la columna \"one\"\n",
    "df.nsmallest(3, \"one\") # els tres registres amb valor més petit en la columna \"one\"\n",
    "\n",
    "print(df.describe()) # taula amb un resum d'estadístiques\n",
    "\n",
    "# Si les dades són no-numèriques mostra altres estadístiques, per exemple en aquesta Serie:\n",
    "\n",
    "obj = pd.Series([\"a\", \"a\", \"b\", \"c\"] * 4)\n",
    "print(obj.describe())\n",
    "\n",
    "print(obj.unique()) # Valors únics de la Serie, com un Set\n",
    "print(obj.value_counts()) # Freqüència de cada valor. # value_counts també està disponible com un method de pandas per ser usat en qualsevol array o seqüència"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Qu1  Qu2  Qu3\n",
      "0    1    2    1\n",
      "1    3    3    5\n",
      "2    4    1    2\n",
      "3    3    2    4\n",
      "4    4    3    4\n",
      "   Qu1  Qu2  Qu3\n",
      "1  1.0  1.0  1.0\n",
      "2  0.0  2.0  1.0\n",
      "3  2.0  2.0  0.0\n",
      "4  2.0  0.0  2.0\n",
      "5  0.0  0.0  1.0\n"
     ]
    }
   ],
   "source": [
    "# Usar value_counts en un DataFrame aplicant-ho a cada columna, per fer, per exemple, un histograma a posteriori\n",
    "\n",
    "data = pd.DataFrame({\"Qu1\": [1, 3, 4, 3, 4], \"Qu2\": [2, 3, 1, 2, 3], \"Qu3\": [1, 5, 2, 4, 4]})\n",
    "print(data)\n",
    "\n",
    "compt = data.apply(pd.value_counts).fillna(0) # fillna: Si algun valor només està en una columna i per tant en les altres surt NaN ho omplirem per 0.\n",
    "\n",
    "print(compt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlació i covariància"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_datareader.data as web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                AAPL       IBM      MSFT      GOOG\n",
      "Date                                              \n",
      "2022-08-19 -0.015102 -0.005034 -0.013854 -0.022671\n",
      "2022-08-22 -0.023029 -0.020380 -0.029355 -0.025821\n",
      "2022-08-23 -0.002029 -0.005976 -0.004716 -0.002607\n",
      "2022-08-24  0.001794 -0.011207 -0.002351 -0.000610\n",
      "2022-08-25  0.007555  0.004916 -0.000073  0.013949\n"
     ]
    }
   ],
   "source": [
    "all_data = {ticker: web.get_data_yahoo(ticker) for ticker in [\"AAPL\", \"IBM\", \"MSFT\", \"GOOG\"]}\n",
    "\n",
    "price = pd.DataFrame({ticker: data[\"Adj Close\"] for ticker, data in all_data.items()})\n",
    "\n",
    "volume = pd.DataFrame({ticker: data[\"Volume\"] for ticker, data in all_data.items()})\n",
    "\n",
    "returns = price.pct_change() # Compute percent changes of the prices (it's a time series operation)\n",
    "\n",
    "print(returns.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          AAPL       IBM      MSFT      GOOG\n",
      "AAPL  1.000000  0.436557  0.760095  0.685282\n",
      "IBM   0.436557  1.000000  0.476538  0.444079\n",
      "MSFT  0.760095  0.476538  1.000000  0.787131\n",
      "GOOG  0.685282  0.444079  0.787131  1.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AAPL    0.436557\n",
       "IBM     1.000000\n",
       "MSFT    0.476538\n",
       "GOOG    0.444079\n",
       "dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Correlació/Covariància entre dues columnes, és a dir, dues Series, alineades per l'índex de les files\n",
    "\n",
    "returns[\"MSFT\"].corr(returns[\"IBM\"])  # equivalent returns.MSFT.corr(returns.IBM) perquè són Python attributes\n",
    "returns[\"MSFT\"].cov(returns[\"IBM\"])\n",
    "\n",
    "# Si volem la taula relacional de totes\n",
    "print(returns.corr())\n",
    "\n",
    "# Si volem la correlació/covariància entre una columna(o fila) del DataFrame i una altra Serie o DataFrame, alineats pels índexs:\n",
    "\n",
    "returns.corrwith(returns.IBM) # Correlació del DataFrame anterior amb la Serie IBM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data\n",
    "\n",
    "### Cargar datos desde fuentes externas como bases de datos, ficheros, llamadas remotas a APIs... y convertirlo en DataFrame.\n",
    "\n",
    "    - df = pd.read_csv(\"examples/ex1.csv\")  (use comma as default delimiter)\n",
    "\n",
    "    - read_table    (use tab \"\\t\" as default delimiter)\n",
    "\n",
    "    - read_excel    (necessary to install with \"pip\", \"xlrd\" and/or \"openpyxl\" packages to read xls and xlsx files respectively)\n",
    "\n",
    "    - read_html\n",
    "\n",
    "    - read_json     (JSON- JavaScript Object Notation)\n",
    "\n",
    "    - read_sas\n",
    "\n",
    "    - read_sql\n",
    "\n",
    "    - read_stata\n",
    "\n",
    "    - read_hdf      (HDF5 Format) - Intended for storing large quantities of scientific array data. HDF in HDF5 stands for hierarchical data format. Each HDF5 file can store multiple datasets and supporting metadata. It can be a good choice for working with very large datasets that don't fit into memory.\n",
    "\n",
    "La función read tiene distintos argumentos, y de hecho alguna de ellas como read_csv tiene hasta 50!\n",
    "\n",
    "### Los argumentos de \"read\" los podemos clasificar en:\n",
    "\n",
    "    - Indexing: Can treat one or more columns as the returned DataFrame, and whether to get column names from the file, the user, or not at all.\n",
    "\n",
    "        - header = None     # avisar que l'arxiu no té labels en les columnes\n",
    "\n",
    "        - names = [\" \", \" \"] # si l'arxiu no té labels en les columnes, els hi podem assignar\n",
    "\n",
    "        - index_col = \" \"   # seleccionar una columna de l'arxiu per ser les labels de les files\n",
    "\n",
    "    - Type inference and data conversion: This includes the user-defined value conversions and custom list of missing value markers.\n",
    "\n",
    "        - pandas detecta expressions de l'arxiu tipus NA, NULL i els transforma en NaN. Si volem que consideri una expressió concreta com NaN\n",
    "\n",
    "            - na_values = [\" \"]\n",
    "\n",
    "            - o passar-li un diccionari que especifiqui per cada columna quines expressions han de ser NaN\n",
    "\n",
    "                - sentinels = {\"columna\": [\"\", \"\"], \"columna\": [\"\"]}\n",
    "\n",
    "    - Datetime parsing: Includes combining capability, including combining date and time information spread over multiple columns into a single column in the result.\n",
    "\n",
    "    - Iterating: Support for iterating over chunks of very large files.\n",
    "\n",
    "        - To read a file in pieces, specify a chunksize as a number of rows. Then read_ returns a TextParser object that allows you to iterate over the parts of the file according to the chunksize.\n",
    "\n",
    "    - Unclean data issues: Skipping rows or a footer, comments, or other minor things like numeric data with thousands separated by commas.\n",
    "\n",
    "        - skiprows = [ ]\n",
    "\n",
    "\n",
    "### Interactuando con Web APIs\n",
    "\n",
    "Many websites have public APIs providing data feeds via JSON or some other format. One easy-to-use method is the \"requests\" library: (import requests)\n",
    "\n",
    "### Interactuando con Databases\n",
    "\n",
    "The SQLAlchemy project is a popular Python SQL toolkit that abstracts away many of the common differences between SQL databases. pandas has a read_sql function that enables you to read data easily from a general SQLAlchemy connection.\n",
    "\n",
    "```python\n",
    "import sqlalchemy as sqla\n",
    "\n",
    "db = sqla.create_engine(\"direcció arxiu\")\n",
    "\n",
    "pd.read_sql(\"select * from name_table\", db) \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export\n",
    "\n",
    "### Exportar una Serie o un DataFrame a otros formatos como una lista, diccionario, DataFrame, csv, json...\n",
    "\n",
    "    - obj.to_list()\n",
    "\n",
    "    - obj.to_dict()\n",
    "\n",
    "    - obj.to_frame()\n",
    "\n",
    "    - obj.to_csv()\n",
    "\n",
    "    - obj.to_json()\n",
    "\n",
    "    - obj.to_excel()\n",
    "\n",
    "    - obj.to_hdf\n",
    "\n",
    "### Alguns dels arguments:\n",
    "\n",
    "    - obj.to_csv(\"examples/out.csv\", sep=\"|\", na_rep=\"NULL\", index=False)\n",
    "\n",
    "        - direcció de guardar, separador, com indicar els valors NaN, no guardar els índexs de files\n",
    "\n",
    "    - df.to_csv(header=False, columns=[\"a\", \"b\"])\n",
    "\n",
    "        - no guardar els índexs de les columnes, guardar només algunes columnes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gestió de cadenes de text\n",
    "\n",
    "Els methods de strings, com ara capitalize, contains, endswith, strip, replace, lower, upper, startswith... són també vàlids en pandas de la següent manera:\n",
    "\n",
    "frame[\"column_name\"].str.capitalize()\n",
    "frame[\"column_name\"].str.replace(\" \", \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regular expressions\n",
    "\n",
    "Junt amb els methods de strings és útil l'ús d'expressions regulars per poder afinar més en la selecció."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gestió de datetimes\n",
    "\n",
    "És habitual haver de gestionar dades en format data, o data-hora. \n",
    "\n",
    "Vegem en un exercici algunes comandes útils:\n",
    "\n",
    "\"Partiendo del fichero oasis.csv que contiene información sobre la discografía del grupo de pop británico Oasis, se pide:\n",
    "\n",
    "Cargue el fichero en un DataFrame.\n",
    "\n",
    "Convierta la columna «album_release_date» a tipo «datetime».\n",
    "\n",
    "Obtenga los nombres de los álbumes publicados entre 2000 y 2005.\"\n",
    "\n",
    "Font: [aprendepython.es][Copyright © 2020, Sergio Delgado Quintero][license GPLV3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album_release_date</th>\n",
       "      <th>album_release_year</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>...</th>\n",
       "      <th>disc_number</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>is_local</th>\n",
       "      <th>track_name</th>\n",
       "      <th>track_number</th>\n",
       "      <th>album_name</th>\n",
       "      <th>key_name</th>\n",
       "      <th>mode_name</th>\n",
       "      <th>key_mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-10-14</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.861</td>\n",
       "      <td>11</td>\n",
       "      <td>-3.410</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0448</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>463213</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>D'You Know What I Mean? - Remastered</td>\n",
       "      <td>1</td>\n",
       "      <td>Be Here Now(Remastered)</td>\n",
       "      <td>B</td>\n",
       "      <td>minor</td>\n",
       "      <td>B minor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-10-14</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.971</td>\n",
       "      <td>9</td>\n",
       "      <td>-1.897</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0705</td>\n",
       "      <td>0.002490</td>\n",
       "      <td>0.005450</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>311333</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>My Big Mouth - Remastered</td>\n",
       "      <td>2</td>\n",
       "      <td>Be Here Now(Remastered)</td>\n",
       "      <td>A</td>\n",
       "      <td>minor</td>\n",
       "      <td>A minor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-10-14</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.899</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0540</td>\n",
       "      <td>0.221000</td>\n",
       "      <td>0.033200</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>430373</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Magic Pie - Remastered</td>\n",
       "      <td>3</td>\n",
       "      <td>Be Here Now(Remastered)</td>\n",
       "      <td>C</td>\n",
       "      <td>major</td>\n",
       "      <td>C major</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-10-14</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.821</td>\n",
       "      <td>7</td>\n",
       "      <td>-2.596</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0412</td>\n",
       "      <td>0.082200</td>\n",
       "      <td>0.003010</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>355866</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Stand by Me - Remastered</td>\n",
       "      <td>4</td>\n",
       "      <td>Be Here Now(Remastered)</td>\n",
       "      <td>G</td>\n",
       "      <td>major</td>\n",
       "      <td>G major</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-10-14</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.977</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.115</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0571</td>\n",
       "      <td>0.003890</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>262400</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>I Hope, I Think, I Know - Remastered</td>\n",
       "      <td>5</td>\n",
       "      <td>Be Here Now(Remastered)</td>\n",
       "      <td>D</td>\n",
       "      <td>major</td>\n",
       "      <td>D major</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  album_release_date  album_release_year  danceability  energy  key  loudness  \\\n",
       "0         2016-10-14                2016         0.297   0.861   11    -3.410   \n",
       "1         2016-10-14                2016         0.354   0.971    9    -1.897   \n",
       "2         2016-10-14                2016         0.300   0.879    0    -2.899   \n",
       "3         2016-10-14                2016         0.197   0.821    7    -2.596   \n",
       "4         2016-10-14                2016         0.342   0.977    2    -2.115   \n",
       "\n",
       "   mode  speechiness  acousticness  instrumentalness  ...  disc_number  \\\n",
       "0     0       0.0448      0.000164          0.000211  ...            1   \n",
       "1     0       0.0705      0.002490          0.005450  ...            1   \n",
       "2     1       0.0540      0.221000          0.033200  ...            1   \n",
       "3     1       0.0412      0.082200          0.003010  ...            1   \n",
       "4     1       0.0571      0.003890          0.000393  ...            1   \n",
       "\n",
       "   duration_ms  explicit  is_local                            track_name  \\\n",
       "0       463213     False     False  D'You Know What I Mean? - Remastered   \n",
       "1       311333     False     False             My Big Mouth - Remastered   \n",
       "2       430373     False     False                Magic Pie - Remastered   \n",
       "3       355866     False     False              Stand by Me - Remastered   \n",
       "4       262400     False     False  I Hope, I Think, I Know - Remastered   \n",
       "\n",
       "   track_number               album_name  key_name mode_name  key_mode  \n",
       "0             1  Be Here Now(Remastered)         B     minor   B minor  \n",
       "1             2  Be Here Now(Remastered)         A     minor   A minor  \n",
       "2             3  Be Here Now(Remastered)         C     major   C major  \n",
       "3             4  Be Here Now(Remastered)         G     major   G major  \n",
       "4             5  Be Here Now(Remastered)         D     major   D major  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"oasis.csv\") # Importar l'arxiu a DataFrame\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime64[ns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0   2016-10-14\n",
       "1   2016-10-14\n",
       "2   2016-10-14\n",
       "3   2016-10-14\n",
       "4   2016-10-14\n",
       "Name: album_release_date, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"album_release_date\"] = pd.to_datetime(df[\"album_release_date\"]) # Convertir type de la columna a datetime.\n",
    "\n",
    "print(df[\"album_release_date\"].dtype)\n",
    "df[\"album_release_date\"].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Don't Believe The Truth\" 'Heathen Chemistry' 'Familiar To Millions'\n",
      " 'Familiar To Millions - The Highlights' 'Familiar To Millions (Live)'\n",
      " 'Standing On The Shoulder Of Giants' 'Standing on the Shoulder of Giants'\n",
      " 'Fmiliar to millions']\n"
     ]
    }
   ],
   "source": [
    "album_names = df[(df[\"album_release_date\"].dt.year <= 2005) & (df[\"album_release_date\"].dt.year >= 2000)][\"album_name\"]\n",
    "\n",
    "print(album_names.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gestió de Categories\n",
    "\n",
    "Las categorías pueden ser tanto datos numéricos como textuales, con la característica de tener un número discreto (relativamente pequeño) de elementos y, en ciertas ocasiones, un orden preestablecido. Ejemplos de variables categóricas son: género, idioma, meses del año, color de ojos, nivel de estudios, grupo sanguíneo, valoración, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Birthday</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Profesion</th>\n",
       "      <th>Studies_level</th>\n",
       "      <th>Edat</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Judit</th>\n",
       "      <td>1989-04-12</td>\n",
       "      <td>Femení</td>\n",
       "      <td>Matemàtica</td>\n",
       "      <td>Universitat</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clàudia</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Femení</td>\n",
       "      <td>Estudiant</td>\n",
       "      <td>Primària</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Israel</th>\n",
       "      <td>1975-09-17</td>\n",
       "      <td>Masculí</td>\n",
       "      <td>Informàtic</td>\n",
       "      <td>FP</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pau</th>\n",
       "      <td>1983-05-23</td>\n",
       "      <td>Masculí</td>\n",
       "      <td>Infermer</td>\n",
       "      <td>FP</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Birthday   Gender   Profesion Studies_level  Edat\n",
       "Name                                                       \n",
       "Judit   1989-04-12   Femení  Matemàtica   Universitat    33\n",
       "Clàudia 2010-01-01   Femení   Estudiant      Primària    12\n",
       "Israel  1975-09-17  Masculí  Informàtic            FP    47\n",
       "Pau     1983-05-23  Masculí    Infermer            FP    39"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas.api.types import CategoricalDtype\n",
    "import datetime\n",
    "\n",
    "# DataFrame creat en que cada llista és una columna\n",
    "#data2 = {\"Nom\": [\"Israel\", \"Judit\", \"Pau\", \"Clàudia\"], \"Data naixement\": [1975, 1989, 1983, 2010], \"Edat\": [47, 33, 39, 12], \"Gènere\": [\"Masculí\", \"Femení\", \"Masculí\", \"Femení\"], \"Professió\": [\"Informàtic\", \"Matemàtica\", \"Infermer\", \"Estudiant\"], \"Nivell d'estudis\": [\"FP\", \"Universitat\", \"FP\", \"Primària\"]}\n",
    "    \n",
    "#df2 = pd.DataFrame(data=data)\n",
    "#df2 = df2.set_index(\"Nom\")\n",
    "#print(df2)\n",
    "\n",
    "# DataFrame creat en que cada llista és un registre\n",
    "data = [[\"Israel\", \"17/09/1975\", \"Masculí\", \"Informàtic\", \"FP\"], [\"Judit\", \"12/04/1989\", \"Femení\", \"Matemàtica\", \"Universitat\"], [\"Pau\", \"23/05/1983\", \"Masculí\", \"Infermer\", \"FP\"], [\"Clàudia\", \"01/01/2010\", \"Femení\", \"Estudiant\", \"Primària\"]]\n",
    "\n",
    "df = pd.DataFrame(data=data, columns=[\"Name\", \"Birthday\", \"Gender\", \"Profesion\", \"Studies_level\"])\n",
    "df = df.set_index(\"Name\")\n",
    "\n",
    "df[\"Birthday\"] = pd.to_datetime(df[\"Birthday\"], format=\"%d/%m/%Y\") # Columna data_naix a format datetime\n",
    "df[\"Edat\"] = pd.to_datetime(\"today\").year - df[\"Birthday\"].dt.year # Creem columna nova \"Edat\"\n",
    "\n",
    "df[\"Gender\"].astype(\"category\")\n",
    "\n",
    "levels = (\"Primària\", \"ESO\", \"BAT\", \"FP\", \"Universitat\")\n",
    "cat_levels = CategoricalDtype(categories=levels, ordered=True)\n",
    "df[\"Studies_level\"] = df[\"Studies_level\"].astype(cat_levels)\n",
    "\n",
    "df.sort_values(by=\"Gender\") # Ordena alfabèticament perquè no hem definit ordre en la categoria\n",
    "\n",
    "df.sort_values(by=[\"Studies_level\", \"Edat\"]) # Aquí sí ordena segons l'ordre establert, i els empatats, per edat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gestió de valors nuls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A    B    C\n",
      "0  1  4.0  7.0\n",
      "1  2  NaN  8.0\n",
      "2  3  6.0  NaN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A     B     C\n",
       "0  2   5.0   8.0\n",
       "1  3  11.0   9.0\n",
       "2  4   7.0  11.0"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4., np.nan, 6.], \"C\": [7., 8., np.nan]})\n",
    "\n",
    "print(df)\n",
    "\n",
    "df.isna() # Taula de True/False segons NaN o no.\n",
    "\n",
    "df.dropna() # Elimina tots els registres que contenen algun NaN\n",
    "\n",
    "df.fillna(0) # Omplir els NaN pel valor desitjat\n",
    "\n",
    "df.interpolate() # Interpola per omplir els NaN\n",
    "\n",
    "df.ffill() # Si hi ha valors NaN, els reemplaça pel valor de la fila prèvia o si axis=\"columns\", pel de la columna prèvia. Vàlid també per exemple en un reindex \n",
    "# obj4.reindex([\"California\", \"Oregon\", \"Ohio\", \"Utah\"], method = \"ffill\") perquè poden quedar de sobte NaNs si hi ha columnes noves.\n",
    "df.ffill(axis=1)\n",
    "\n",
    "df.add(1, fill_value = 10) # fill_value = valor, si hi ha valors NaN hi posa aquest valor i després fa l'operació."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remodelar un DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format ample i format llarg\n",
    "\n",
    "- Format ample: Cada fila té múltiples columnes que representen les variables d'una mateixa observació. És el format habitual d'un DataFrame.\n",
    "\n",
    "- Format llarg: Cada fila té tres columnes, una que identifica l'observació, una que indica la variable i l'altra que indica el valor d'aquesta variable.\n",
    "\n",
    "D'ample a llarg: df.melt(id_vars=\" \")\n",
    "\n",
    "De llarg a ample: df.pivot(index=\" \", columns='variable', values='value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apilar les dades\n",
    "\n",
    "- Format índex multinivell: Agrupa per índex les columnes.\n",
    "\n",
    "- Format índex senzill: Aplana el dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Company  Revenue  Employees        City        Country\n",
      "0     Apple   274515     147000  California  United States\n",
      "1   Samsung   200734     267937       Suwon    South Korea\n",
      "2  Alphabet   182527     135301  California  United States\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Employees</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple</td>\n",
       "      <td>274515</td>\n",
       "      <td>147000</td>\n",
       "      <td>California</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Samsung</td>\n",
       "      <td>200734</td>\n",
       "      <td>267937</td>\n",
       "      <td>Suwon</td>\n",
       "      <td>South Korea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alphabet</td>\n",
       "      <td>182527</td>\n",
       "      <td>135301</td>\n",
       "      <td>California</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Company  Revenue  Employees        City        Country\n",
       "0     Apple   274515     147000  California  United States\n",
       "1   Samsung   200734     267937       Suwon    South Korea\n",
       "2  Alphabet   182527     135301  California  United States"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"Company\": [\"Apple\", \"Samsung\", \"Alphabet\"], \"Revenue\": [274515, 200734, 182527], \"Employees\": [147000, 267937, 135301], \"City\": [\"California\", \"Suwon\", \"California\"], \"Country\": [\"United States\", \"South Korea\", \"United States\"]})\n",
    "print(df)\n",
    "\n",
    "# D'ample a llarg\n",
    "df_long = df.melt(id_vars=\"Company\")\n",
    "df_long\n",
    "\n",
    "# De llarg a ample\n",
    "df_anch = df_long.pivot(index=\"Company\", columns=\"variable\", values=\"value\")\n",
    "\n",
    "df_anch = df.rename_axis(columns = None) # per treure el name attribute \"variable\" de les columnes\n",
    "df_anch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company            \n",
      "Apple     Revenue             274515\n",
      "          Employees           147000\n",
      "          City            California\n",
      "          Country      United States\n",
      "Samsung   Revenue             200734\n",
      "          Employees           267937\n",
      "          City                 Suwon\n",
      "          Country        South Korea\n",
      "Alphabet  Revenue             182527\n",
      "          Employees           135301\n",
      "          City            California\n",
      "          Country      United States\n",
      "dtype: object\n",
      "         Revenue Employees        City        Country\n",
      "Company                                              \n",
      "Apple     274515    147000  California  United States\n",
      "Samsung   200734    267937       Suwon    South Korea\n",
      "Alphabet  182527    135301  California  United States\n"
     ]
    }
   ],
   "source": [
    "# Format índex multinivell\n",
    "df = pd.DataFrame({\"Company\": [\"Apple\", \"Samsung\", \"Alphabet\"], \"Revenue\": [274515, 200734, 182527], \"Employees\": [147000, 267937, 135301], \"City\": [\"California\", \"Suwon\", \"California\"], \"Country\": [\"United States\", \"South Korea\", \"United States\"]})\n",
    "\n",
    "df.set_index(\"Company\", inplace=True) # Apilar treballa sobre l'índex del DataFrame, considerem que sigui \"Company\"\n",
    "\n",
    "df_stacked = df.stack()\n",
    "print(df_stacked)\n",
    "df_stacked.index\n",
    "\n",
    "df_flat = df_stacked.unstack()\n",
    "print(df_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agrupar dades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Population     Area Province  Green\n",
      "Island                                            \n",
      "Gran Canaria       855521  1560.10     LPGC  False\n",
      "Tenerife           928604  2034.38     SCTF  False\n",
      "La Palma            83458   708.32     SCTF  False\n",
      "Lanzarote          155812   845.94     LPGC  False\n",
      "La Gomera           21678   369.76     SCTF   True\n",
      "El Hierro           11147   278.71     SCTF   True\n",
      "Fuerteventura      119732  1659.00     LPGC   True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Population</th>\n",
       "      <th>Area</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Province</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LPGC</th>\n",
       "      <td>377021.666667</td>\n",
       "      <td>4065.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCTF</th>\n",
       "      <td>261221.750000</td>\n",
       "      <td>3391.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Population     Area\n",
       "Province                        \n",
       "LPGC      377021.666667  4065.04\n",
       "SCTF      261221.750000  3391.17"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"democan.csv\", index_col=\"Island\")\n",
    "df[\"Green\"] = [False, False, False, False, True, True, True]\n",
    "print(df)\n",
    "\n",
    "df.groupby(\"Province\").sum()\n",
    "# df.groupby(\"Province\")[\"Population\"].sum() # Només una columna\n",
    "\n",
    "df_sum = df.groupby([\"Province\", \"Green\"]).sum() # Dos agrupaments. És com format multiíndex.\n",
    "df_sum\n",
    "#df_flat = df_sum.unstack() # Podríem aplanar el DataFrame anterior.\n",
    "\n",
    "df_vc = df.groupby(\"Province\")[\"Green\"].value_counts()\n",
    "df_vc\n",
    "\n",
    "# Diferents funcions per columna\n",
    "\n",
    "df_multi = df.groupby(\"Province\").agg({\"Population\": \"mean\", \"Area\": \"sum\" })\n",
    "df_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Population     Area Province\n",
      "Island                                     \n",
      "Gran Canaria       855521  1560.10     LPGC\n",
      "Tenerife           928604  2034.38     SCTF\n",
      "La Palma            83458   708.32     SCTF\n",
      "Lanzarote          155812   845.94     LPGC\n",
      "La Gomera           21678   369.76     SCTF\n",
      "El Hierro           11147   278.71     SCTF\n",
      "Fuerteventura      119732  1659.00     LPGC\n",
      "Province\n",
      "LPGC    1131065\n",
      "SCTF    1044887\n",
      "Name: Population, dtype: int64\n",
      "Province\n",
      "LPGC    0.519802\n",
      "SCTF    0.480198\n",
      "Name: Population, dtype: float64\n",
      "El percentatge de població de cada provincia respecte el total és d'un 52% per Las Palmas de Gran Canaria i d'un 48% per Santa Cruz de Tenerife\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"democan.csv\", index_col=\"Island\")\n",
    "print(df)\n",
    "\n",
    "total_population = df[\"Population\"].sum()\n",
    "\n",
    "df_pop_by_prov = df.groupby(\"Province\")[\"Population\"].sum() # En seleccionar només la columna Population ara tenim una Serie\n",
    "print(df_pop_by_prov)\n",
    "\n",
    "df_pc = df_pop_by_prov.div(total_population)\n",
    "print(df_pc)\n",
    "\n",
    "pc_LPGC = df_pc[\"LPGC\"] * 100\n",
    "pc_SCTF = df_pc[\"SCTF\"] * 100\n",
    "\n",
    "print(f\"El percentatge de població de cada provincia respecte el total és d'un {round(pc_LPGC)}% per Las Palmas de Gran Canaria i d'un {round(pc_SCTF)}% per Santa Cruz de Tenerife\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
